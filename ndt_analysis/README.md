# NDT Feature Selection Pipeline

**Masterarbeit:** ZerstÃ¶rungsfreie WerkstoffprÃ¼fung mittels 3MA-X8-Mikromagnetik
**Methodik:** Vierstufige Feature-Selektions-Pipeline fÃ¼r LDA/QDA-Klassifikation

---

## Ãœbersicht

Diese Pipeline reduziert einen initialen 261-dimensionalen Feature-Space auf ein robustes, methodenagnostisches Subset zur Material- und Zustands-Klassifikation.

### Pipeline-Architektur

```
Phase 1: QualitÃ¤tsfilterung & Korrelations-Prepruning
         261 Features â†’ ~84 Features
         â”œâ”€ Missing Values Filter (>15%)
         â”œâ”€ Near-Zero Variance Filter
         â”œâ”€ OvR-Signal Berechnung
         â””â”€ Hierarchisches Clustering (|Ï| â‰¥ 0.90)

Phase 2: Multi-Methoden Feature-Ranking
         8 unabhÃ¤ngige Ranking-Methoden (Fold-Aware)
         â”œâ”€ ANOVA F-Test
         â”œâ”€ Mutual Information
         â”œâ”€ mRMR
         â”œâ”€ ReliefF
         â”œâ”€ L1-Lasso
         â”œâ”€ Random Forest
         â”œâ”€ Permutation Importance
         â””â”€ PCA-Importance

Phase 3: Iterative Reduktions-Evaluierung
         LDA/QDA Benchmarking (10 Stufen Ã— 8 Rankings)
         â””â”€ 5-Fold GroupKFold CV mit 95% CI

Phase 4: Konsensus-Analyse
         Methodenagnostisches Core-Set
         â””â”€ Rang-Normalisierung + Mittelung
```

---

## Installation

### Voraussetzungen

- Python 3.9+
- JupyterHub oder lokale Jupyter-Installation

### Setup auf JupyterHub

1. **Repository hochladen:**
   ```bash
   # Falls Git verfÃ¼gbar:
   git clone <your-repo-url>
   cd ndt_analysis

   # Oder: Dateien manuell hochladen
   ```

2. **Dependencies installieren:**
   ```bash
   pip install -r requirements.txt
   ```

3. **Datenstruktur vorbereiten:**
   ```
   ndt_analysis/
   â”œâ”€â”€ data/
   â”‚   â””â”€â”€ raw/
   â”‚       â””â”€â”€ 3ma_x8_features.csv  # <-- IHRE DATEN HIER!
   ```

---

## Datenformat

### Erwartete CSV-Struktur

Ihre Datei `3ma_x8_features.csv` sollte folgendes Format haben:

| sample_id | class | feature_1 | feature_2 | ... | feature_261 |
|-----------|-------|-----------|-----------|-----|-------------|
| P001      | A     | 0.123     | 0.456     | ... | 0.789       |
| P001      | A     | 0.124     | 0.457     | ... | 0.790       |
| P002      | B     | 0.234     | 0.567     | ... | 0.891       |

**Kritische Spalten:**

- `sample_id`: Proben-ID fÃ¼r GroupKFold (verhindert Data Leakage)
- `class`: Zielvariable (Material-/Zustandsklasse)
- `feature_1` ... `feature_261`: Ihre 3MA-X8 Features

### Anpassung an Ihre Daten

In jedem Notebook mÃ¼ssen Sie **zwei Zeilen** anpassen:

```python
# ANPASSEN: Dateipfad
DATA_PATH = '../data/raw/3ma_x8_features.csv'  # <-- Ihr Dateipfad

# ANPASSEN: Spaltennamen
TARGET_COL = 'class'       # <-- Name Ihrer Zielvariablen-Spalte
GROUP_COL = 'sample_id'    # <-- Name Ihrer Proben-ID-Spalte
```

---

## Verwendung

### 1. Notebooks nacheinander ausfÃ¼hren

Die Notebooks mÃ¼ssen **in Reihenfolge** ausgefÃ¼hrt werden:

```
01_Phase1_Filtering_Prepruning.ipynb
  â†“ (erzeugt: features_after_phase1.csv)

02_Phase2_Multi_Method_Ranking.ipynb
  â†“ (erzeugt: 8 Ranking-CSVs)

03_Phase3_Evaluation_Benchmarking.ipynb
  â†“ (erzeugt: Pareto-Kurven, Performance-Tabellen)

04_Phase4_Consensus_Analysis.ipynb
  â†“ (erzeugt: Finales Konsensus-Ranking)
```

### 2. Workflow pro Notebook

Jedes Notebook ist in Sektionen unterteilt:

1. **Daten laden** â†’ Passen Sie Dateipfade an
2. **Verarbeitung** â†’ FÃ¼hren Sie alle Zellen aus
3. **Visualisierung** â†’ Plots werden inline angezeigt
4. **Ergebnisse speichern** â†’ CSV/PNG werden automatisch gespeichert

### 3. AusfÃ¼hrungszeit

**GeschÃ¤tzte Laufzeit (Intel i5, 16GB RAM):**

- Notebook 1: ~2-5 Minuten
- Notebook 2: ~10-20 Minuten âš ï¸ (8 Methoden Ã— 5 Folds)
- Notebook 3: ~30-60 Minuten âš ï¸ (800 CV-Trainings!)
- Notebook 4: ~10-15 Minuten

**TIPP:** Notebook 3 ist rechenintensiv. FÃ¼hren Sie es idealerweise Ã¼ber Nacht aus oder reduzieren Sie `n_splits=5` â†’ `n_splits=3`.

---

## Outputs

### Verzeichnisstruktur nach AusfÃ¼hrung

```
ndt_analysis/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ 3ma_x8_features.csv         # Input
â”‚   â””â”€â”€ processed/
â”‚       â””â”€â”€ features_after_phase1.csv   # Nach Phase 1
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ rankings/
â”‚   â”‚   â”œâ”€â”€ phase1_feature_info.csv
â”‚   â”‚   â”œâ”€â”€ phase2_ranking_ANOVA.csv
â”‚   â”‚   â”œâ”€â”€ phase2_ranking_MutualInfo.csv
â”‚   â”‚   â”œâ”€â”€ ... (8 Rankings)
â”‚   â”‚   â”œâ”€â”€ phase4_consensus_ranking_full.csv      # â˜… FINALES RANKING
â”‚   â”‚   â””â”€â”€ phase4_optimal_features.csv            # â˜… EMPFOHLENES SET
â”‚   â”œâ”€â”€ evaluations/
â”‚   â”‚   â”œâ”€â”€ phase3_evaluation_master.csv           # Alle Benchmarks
â”‚   â”‚   â”œâ”€â”€ phase4_consensus_evaluation.csv
â”‚   â”‚   â””â”€â”€ phase4_method_comparison.csv
â”‚   â””â”€â”€ plots/
â”‚       â”œâ”€â”€ phase1_correlation_heatmap.png
â”‚       â”œâ”€â”€ phase2_ranking_comparison.png
â”‚       â”œâ”€â”€ phase3_pareto_lda.png
â”‚       â”œâ”€â”€ phase3_pareto_qda.png
â”‚       â””â”€â”€ phase4_consensus_pareto_lda.png
```

### Wichtigste Dateien fÃ¼r Ihre Arbeit

| Datei | Beschreibung | Verwendung |
|-------|--------------|------------|
| `phase4_consensus_ranking_full.csv` | Komplettes Konsensus-Ranking | Methodenagnostisches Ranking |
| `phase4_optimal_features.csv` | Empfohlenes Feature-Set (Elbow-Point) | Verwenden Sie diese Features! |
| `phase3_evaluation_master.csv` | Alle Performance-Benchmarks | Methodenvergleich, Tabellen |
| `phase3_pareto_lda.png` | Pareto-Kurven LDA | Visualisierung fÃ¼r Paper |

---

## Methodische Details

### Kritische Aspekte

#### 1. GroupKFold Cross-Validation

**Warum?** Mehrfachmessungen derselben Probe dÃ¼rfen nicht auf Train/Test aufgeteilt werden!

```python
# RICHTIG:
gkf = GroupKFold(n_splits=5)
for train_idx, test_idx in gkf.split(X, y, groups=sample_ids):
    ...

# FALSCH (Data Leakage!):
kf = KFold(n_splits=5)
for train_idx, test_idx in kf.split(X, y):
    ...
```

#### 2. Preprocessing innerhalb CV-Folds

**Warum?** Imputation/Skalierung auf gesamten Daten fÃ¼hrt zu Overfitting-Bias!

```python
# RICHTIG (Pipeline):
pipeline = Pipeline([
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler()),
    ('classifier', LinearDiscriminantAnalysis())
])
pipeline.fit(X_train, y_train)  # Fit nur auf Train!

# FALSCH:
scaler.fit(X)  # Fit auf gesamten Daten!
X_scaled = scaler.transform(X)
# Dann CV...
```

#### 3. Konfidenzintervalle mit t-Verteilung

Bei 5 Folds haben wir nur 5 Datenpunkte â†’ t-Verteilung (df=4) statt z-Verteilung!

```python
from scipy import stats
t_critical = stats.t.ppf(0.975, df=4)  # 95% CI, 2-seitig
```

### Parameter-Tuning

Falls Sie Parameter anpassen mÃ¶chten:

#### Phase 1: Korrelationsschwellwert

```python
# Im Notebook Ã¤ndern:
CORR_THRESHOLD = 0.90  # Standard
# ErhÃ¶hen â†’ weniger Features eliminiert (konservativer)
# Senken â†’ mehr Features eliminiert (aggressiver)
```

#### Phase 2: Random Forest Hyperparameter

```python
rf = RandomForestClassifier(
    n_estimators=100,      # Mehr â†’ stabiler, aber langsamer
    max_depth=10,          # Kleiner bei Overfitting
    min_samples_split=5,   # GrÃ¶ÃŸer bei Overfitting
    random_state=42
)
```

#### Phase 3: QDA Regularisierung

```python
qda = QuadraticDiscriminantAnalysis(
    reg_param=0.1  # ErhÃ¶hen bei SingularitÃ¤ts-Fehlern!
)
```

---

## Troubleshooting

### Problem 1: "Singular matrix" (QDA)

**Ursache:** Zu wenige Samples pro Klasse fÃ¼r QDA-KovarianzschÃ¤tzung.

**LÃ¶sung:**
```python
# ErhÃ¶hen Sie reg_param:
qda = QuadraticDiscriminantAnalysis(reg_param=0.5)  # statt 0.1
```

### Problem 2: Notebook 2 dauert sehr lange

**LÃ¶sung:**
```python
# Reduzieren Sie CV-Folds:
n_splits = 3  # statt 5

# Oder: Reduzieren Sie Random Forest Estimators:
n_estimators = 50  # statt 100
```

### Problem 3: "Feature not found in DataFrame"

**Ursache:** Spaltennamen passen nicht.

**LÃ¶sung:** ÃœberprÃ¼fen Sie:
```python
print(df.columns.tolist())  # Alle Spaltennamen anzeigen
```

### Problem 4: Memory Error bei Notebook 3

**LÃ¶sung:**
```python
# Reduzieren Sie Reduktionsstufen:
REDUCTION_PERCENTAGES = [0.80, 0.60, 0.40, 0.20, 0.10]  # statt 10 Stufen
```

---

## Interpretation der Ergebnisse

### Pareto-Kurven

**Was zeigen sie?**
Trade-off zwischen Feature-Anzahl (x-Achse) und Performance (y-Achse).

**Wie interpretieren?**
- **Elbow-Point:** Stelle, an der weitere Features kaum noch Performance bringen
- **Steile Anstiege:** Diese Features sind kritisch
- **Flache Bereiche:** Redundante Features

**Beispiel:**
```
Performance
    â”‚
0.9 â”‚         â•­â”€â”€â”€â”€â”€â”€â”€â”€  (Plateau: Redundanz)
    â”‚        â•±
0.8 â”‚       â•± â† Elbow (optimal!)
    â”‚      â•±
0.7 â”‚     â•±
    â”‚____â•±________________
        10   20   30   40  Features
```

### Konsensus-Score

**Was bedeutet er?**
Mittelwert der normalisierten RÃ¤nge Ã¼ber alle 8 Methoden.

- **Score â‰ˆ 1.0:** Feature wird von ALLEN Methoden als wichtig eingestuft â†’ sehr robust
- **Score â‰ˆ 0.5:** MittelmÃ¤ÃŸige Wichtigkeit
- **Score â‰ˆ 0.0:** Feature wird von den meisten Methoden als unwichtig eingestuft

### Rang-Varianz

**Was bedeutet sie?**
Wie stark schwanken die RÃ¤nge eines Features Ã¼ber die Methoden?

- **Niedrige Varianz:** Konsens zwischen Methoden â†’ robust
- **Hohe Varianz:** Uneinigkeit â†’ methodenabhÃ¤ngig, vorsichtig verwenden

---

## Referenzen

### Implementierte Methoden

1. **ANOVA F-Test:**
   Fisher, R.A. (1925). Statistical Methods for Research Workers.

2. **Mutual Information:**
   Cover, T.M., Thomas, J.A. (2006). Elements of Information Theory.

3. **mRMR:**
   Peng, H., et al. (2005). Feature selection based on mutual information.

4. **ReliefF:**
   Kononenko, I. (1994). Estimating attributes: Analysis and extensions of RELIEF.

5. **L1-Lasso:**
   Tibshirani, R. (1996). Regression shrinkage and selection via the lasso.

6. **Random Forest:**
   Breiman, L. (2001). Random Forests.

7. **Permutation Importance:**
   Breiman, L. (2001). Statistical modeling: The two cultures.

8. **PCA:**
   Pearson, K. (1901). On lines and planes of closest fit to systems of points in space.

### Validierungsstrategien

- **GroupKFold:**
  Sklearn Documentation - GroupKFold

- **Konfidenzintervalle:**
  Student's t-distribution (Gosset, W.S., 1908)

---

## Kontakt & Support

Bei Fragen zur Implementierung oder Methodik:

1. ÃœberprÃ¼fen Sie die **Markdown-Zellen** in den Notebooks (enthalten methodische ErklÃ¤rungen)
2. Konsultieren Sie die **Spezifikation** am Anfang dieses Projekts
3. PrÃ¼fen Sie die **Utility-Module** (`ndt_analysis/utils/`) fÃ¼r technische Details

---

## Lizenz

Dieses Projekt wurde fÃ¼r akademische Forschung entwickelt (Masterarbeit NDT/3MA-X8).
Verwendung fÃ¼r eigene Forschungsprojekte ausdrÃ¼cklich erlaubt.

---

**Viel Erfolg mit Ihrer Masterarbeit!** ğŸ“
